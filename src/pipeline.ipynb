{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üç´ Building a Controlnet pipeline for interior design with Fondant\n",
    "\n",
    "> ‚ö†Ô∏è Please note that this notebook **is not** compatible with **Google Colab**. To complete the tutorial, you must\n",
    "> initiate Docker containers. Starting Docker containers within Google Colab is not supported.\n",
    "\n",
    "This example demonstrates an end-to-end fondant pipeline to collect and process data for the fine-tuning of a [ControlNet](https://github.com/lllyasviel/ControlNet) model, focusing on images related to interior design.\n",
    "\n",
    "\n",
    "### Pipeline overview\n",
    "\n",
    "\n",
    "There are 5 components in total, these are:\n",
    "\n",
    "1. [**Prompt Generation**](components/generate_prompts): This component generates a set of seed prompts using a rule-based approach that combines various rooms and styles together, like ‚Äúa photo of a {room_type} in the style of {style_type}‚Äù. As input, it takes in a list of room types (bedroom, kitchen, laundry room, ..), a list of room styles (contemporary, minimalist, art deco, ...) and a list of prefixes (comfortable, luxurious, simple). These lists can be easily adapted to other domains. The output of this component is a list of seed prompts.\n",
    "\n",
    "2. [**Image URL Retrieval**](https://github.com/ml6team/fondant/tree/main/components/prompt_based_laion_retrieval): This component retrieves images from the [LAION-5B](https://laion.ai/blog/laion-5b/) dataset based on the seed prompts. The retrieval itself is done based on CLIP embeddings similarity between the prompt sentences and the captions in the LAION dataset. This component doesn‚Äôt return the actual images yet, only the URLs. The next component in the pipeline will then download these images.\n",
    "\n",
    "3. [**Download Images**](https://github.com/ml6team/fondant/tree/main/components/download_images): This component downloads the actual images based on the URLs retrieved by the previous component. It takes in the URLs as input and returns the actual images, along with some metadata (like their height and width).\n",
    "\n",
    "4. [**Add Captions**](https://github.com/ml6team/fondant/tree/main/components/caption_images): This component captions all images using [BLIP](https://huggingface.co/docs/transformers/model_doc/blip). This model takes in the image and generates a caption that describes the content of the image. This component takes in a Hugging Face model ID, so it can use any [Hugging Face Hub model](https://huggingface.co/models).\n",
    "\n",
    "5. [**Add Segmentation Maps**](https://github.com/ml6team/fondant/tree/main/components/segment_images): This component segments the images using the [UPerNet](https://huggingface.co/docs/transformers/model_doc/upernet) model. Each segmentation map contains segments of 150 possible categories listed [here](https://huggingface.co/openmmlab/upernet-convnext-small/blob/main/config.json#L110)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n",
    "\n",
    "#### This section checks the prerequisites of your environment. Read any errors or warnings carefully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ensure a Python between version 3.8 and 3.10 is available**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if sys.version_info < (3, 8, 0) or sys.version_info >= (3, 11, 0):\n",
    "    raise Exception(f\"A Python version between 3.8 and 3.10 is required. You are running {sys.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check if docker compose is installed and the docker daemon is running**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker compose version >/dev/null\n",
    "!docker info >/dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check if GPU is available**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import subprocess\n",
    "\n",
    "try:\n",
    "    subprocess.check_output('nvidia-smi')\n",
    "    logging.info(\"Found GPU, using it!\")\n",
    "    number_of_accelerators = 1\n",
    "    accelerator_name = \"GPU\"\n",
    "except Exception:\n",
    "    logging.warning(\"We recommend to run this pipeline on a GPU, but none could be found, using CPU instead\")\n",
    "    number_of_accelerators = None\n",
    "    accelerator_name = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make sure Fondant is installed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r ../requirements.txt -q --disable-pip-version-check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement the pipeline\n",
    "\n",
    "### Creating a pipeline\n",
    "\n",
    "First of all, we need to initialize the pipeline, which includes specifying a name for your pipeline, providing a description, and setting a base_path. The base_path is used to store the pipeline artifacts and data generated by the components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from fondant.pipeline import ComponentOp, Pipeline, Resources\n",
    "\n",
    "BASE_PATH = \"./data_dir\"\n",
    "Path(BASE_PATH).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    pipeline_name=\"controlnet-pipeline\",\n",
    "    pipeline_description=\"Pipeline that collects data to train ControlNet\",\n",
    "    base_path=BASE_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a (custom) component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first component of our pipeline is the `generate_prompts` component, which generates seed prompts. This is a custom component implemented in this repository. You can find it at [./components/generate_prompts](./components/generate_prompts).\n",
    "\n",
    "To create an operation for a custom component, we create a `ComponentOp` and pass in the `component_dir` where the component is located.\n",
    "\n",
    "We can pass in arguments to change the behavior of the component. Here we are passing in `n_rows_to_load: 10`, which limits the amount of data that is generated for the purpose of this example.\n",
    "\n",
    "For an overview of the available arguments, you can check the [`fondant_component.yaml`](/edit/src/components/generate_prompts/fondant_component.yaml) specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_prompts_op = ComponentOp(\n",
    "    component_dir=\"components/generate_prompts\",\n",
    "    arguments={\n",
    "        \"n_rows_to_load\": 10\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we've created an operation for our component, we can add it to our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.add_op(generate_prompts_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, our pipeline consists of a single component that generates prompts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding more (reusable) components\n",
    "\n",
    "We can now proceed to add more components. \n",
    "\n",
    "We will use components available on the [Fondant Hub](https://fondant.ai/en/latest/components/hub/), for which we can create operations using the `ComponentOp.from_registry(...)` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*NOTE: The `prompt_based_laion_retrieval` component uses a public CLIP service which can only handle a few requets at a time, if you run into [timeout issues](https://github.com/rom1504/clip-retrieval/issues/267), you might want to host your own clip service following this [guide](https://github.com/rom1504/clip-retrieval/blob/main/docs/laion5B_h14_back.md)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laion_retrieval_op = ComponentOp.from_registry(\n",
    "    name=\"prompt_based_laion_retrieval\",\n",
    "    arguments={\n",
    "        \"num_images\": 3,\n",
    "        \"aesthetic_score\": 9,\n",
    "        \"aesthetic_weight\": 0.5,\n",
    "        \"url\": \"https://knn.laion.ai/knn-service\"\n",
    "    },\n",
    ")\n",
    "\n",
    "download_images_op = ComponentOp.from_registry(\n",
    "    name=\"download_images\",\n",
    "    arguments={\n",
    "        \"timeout\": 1,\n",
    "        \"retries\": 0,\n",
    "        \"image_size\": 512,\n",
    "        \"resize_mode\": \"center_crop\",\n",
    "        \"resize_only_if_bigger\": False,\n",
    "        \"min_image_size\": 0,\n",
    "        \"max_aspect_ratio\": 2.5,\n",
    "    },\n",
    ")\n",
    "\n",
    "caption_images_op = ComponentOp.from_registry(\n",
    "    name=\"caption_images\",\n",
    "    arguments={\n",
    "        \"model_id\": \"Salesforce/blip-image-captioning-base\",\n",
    "        \"batch_size\": 8,\n",
    "        \"max_new_tokens\": 50,\n",
    "    },\n",
    "    resources=Resources(\n",
    "        accelerator_number=number_of_accelerators,\n",
    "        accelerator_name=accelerator_name,\n",
    "    ),\n",
    ")\n",
    "\n",
    "segment_images_op = ComponentOp.from_registry(\n",
    "    name=\"segment_images\",\n",
    "    arguments={\n",
    "        \"model_id\": \"openmmlab/upernet-convnext-small\",\n",
    "        \"batch_size\": 8,\n",
    "    },\n",
    "    resources=Resources(\n",
    "        accelerator_number=number_of_accelerators,\n",
    "        accelerator_name=accelerator_name,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use the components in our pipeline. We will chain them into a pipeline by defining dependencies between the different pipeline steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.add_op(laion_retrieval_op, dependencies=generate_prompts_op)\n",
    "pipeline.add_op(download_images_op, dependencies=laion_retrieval_op)\n",
    "pipeline.add_op(caption_images_op, dependencies=download_images_op)\n",
    "pipeline.add_op(segment_images_op, dependencies=caption_images_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: writing the dataset to the Hugging Face Hub "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To write the final dataset to HF hub, we will use the `write_to_hf_hub` component from the [Fondant Hub](https://fondant.ai/en/latest/components/hub/).\n",
    "\n",
    "You'll need a Hugging Face Hub account for this. If you don't have one, you can either create one, or skip this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USERNAME = \n",
    "HF_TOKEN = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`write_to_hf_hub` is a special type of reusable Fondant component which is **generic**. This means that it can handle different data schemas, but we have to tell it which schema to use.\n",
    "\n",
    "We do this by overwriting its `fondant_component.yaml` file with the schema of the data we want it to write. To achieve this, we can create a `fondant_component.yaml` file in the directory `components/write_to_hf_hub` with the following content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile components/write_to_hub_controlnet/fondant_component.yaml\n",
    "name: Write to hub\n",
    "description: Component that writes a dataset to the hub\n",
    "image: fndnt/write_to_hf_hub:0.6.2  # We use a docker image from the Fondant Hub instead of implementing our own.\n",
    "\n",
    "consumes:  # We fill in our data schema here. The component will write this data to the Hugging Face Hub.\n",
    "  images:\n",
    "    fields:\n",
    "      data:\n",
    "        type: binary\n",
    "\n",
    "  captions:\n",
    "    fields:\n",
    "      text:\n",
    "        type: string\n",
    "\n",
    "  segmentations:\n",
    "    fields:\n",
    "      data:\n",
    "        type: binary\n",
    "\n",
    "args:  # We repeat the arguments from the original `fondant_component.yaml`\n",
    "  hf_token:\n",
    "    description: The hugging face token used to write to the hub\n",
    "    type: str\n",
    "  username:\n",
    "    description: The username under which to upload the dataset\n",
    "    type: str\n",
    "  dataset_name:\n",
    "    description: The name of the dataset to upload\n",
    "    type: str\n",
    "  image_column_names:\n",
    "    description: A list containing the image column names. Used to format to image to HF hub format\n",
    "    type: list\n",
    "    default: []\n",
    "  column_name_mapping:\n",
    "    description: Mapping of the consumed fondant column names to the written hub column names\n",
    "    type: dict\n",
    "    default: {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For which we then create an operation as if it was a custom component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_hub_controlnet = ComponentOp(\n",
    "    component_dir=\"components/write_to_hub_controlnet\",\n",
    "    arguments={\n",
    "        \"username\": USERNAME ,\n",
    "        \"hf_token\": HF_TOKEN ,\n",
    "        \"dataset_name\": \"controlnet-interior-design\",\n",
    "        \"image_column_names\": [\"images_data\"],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And add it to the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.add_op(write_to_hub_controlnet, dependencies=segment_images_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the pipeline\n",
    "\n",
    "This pipeline will generate prompts, retrieve matching images in the laion dataset, download then and generate corresponding captions and segmentations. If you added the optional `write_to_hf_hub` component, it will write the resulting dataset to the HF hub.\n",
    "\n",
    "Fondant provides multiple runners to run our pipeline:\n",
    "- A Docker runner for local execution\n",
    "- A Vertex AI runner for managed execution on Google Cloud\n",
    "- A Kubeflow Pipelines runner for execution anywhere\n",
    "\n",
    "Here we will use the `DockerRunner` for local execution, which utilizes docker-compose under the hood.\n",
    "\n",
    "The runner will first build the custom component and download the reusable components from the component hub. Afterwards, you will see the components execute one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are using a MacBook with a M1 processor you have to make sure to set the docker default platform to linux/amd64\n",
    "import os\n",
    "os.environ[\"DOCKER_DEFAULT_PLATFORM\"] = \"linux/amd64\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fondant.pipeline.compiler import DockerCompiler\n",
    "from fondant.pipeline.runner import DockerRunner\n",
    "\n",
    "DockerCompiler().compile(pipeline=pipeline, output_path=\"docker-compose.yml\")\n",
    "DockerRunner().run(\"docker-compose.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also explore the dataset using the fondant explorer, this enables you to visualize your output dataset at each component step. Use the side panel on the left to browse through the steps and subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fondant.explore import run_explorer_app\n",
    "\n",
    "run_explorer_app(\n",
    "    base_path=BASE_PATH,\n",
    "    container=\"fndnt/data_explorer\",\n",
    "    tag=\"latest\",\n",
    "    port=8501,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To stop the Explorer and continue the notebook, press the stop button at the top of the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating your own dataset\n",
    "\n",
    "To create your own dataset, you can update the `generate_prompts` component to generate prompts describing the images you want.\n",
    "\n",
    "Make the changes you want below and press enter, they will be written to the `./components/generate_prompts/src/main.py` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile components/generate_prompts/src/main.py\n",
    "\"\"\"\n",
    "This component generates a set of initial prompts that will be used to retrieve images\n",
    "from the LAION-5B dataset.\n",
    "\"\"\"\n",
    "import itertools\n",
    "import logging\n",
    "import typing as t\n",
    "\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "\n",
    "from fondant.component import DaskLoadComponent\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "interior_styles = [\n",
    "    \"art deco\",\n",
    "    \"bauhaus\",\n",
    "    \"boucl√©\",\n",
    "    \"maximalist\",\n",
    "    \"brutalist\",\n",
    "    \"coastal\",\n",
    "    \"minimalist\",\n",
    "    \"rustic\",\n",
    "    \"hollywood regency\",\n",
    "    \"midcentury modern\",\n",
    "    \"modern organic\",\n",
    "    \"contemporary\",\n",
    "    \"modern\",\n",
    "    \"scandinavian\",\n",
    "    \"eclectic\",\n",
    "    \"bohemiam\",\n",
    "    \"industrial\",\n",
    "    \"traditional\",\n",
    "    \"transitional\",\n",
    "    \"farmhouse\",\n",
    "    \"country\",\n",
    "    \"asian\",\n",
    "    \"mediterranean\",\n",
    "    \"rustic\",\n",
    "    \"southwestern\",\n",
    "    \"coastal\",\n",
    "]\n",
    "\n",
    "interior_prefix = [\n",
    "    \"comfortable\",\n",
    "    \"luxurious\",\n",
    "    \"simple\",\n",
    "]\n",
    "\n",
    "rooms = [\n",
    "    \"Bathroom\",\n",
    "    \"Living room\",\n",
    "    \"Hotel room\",\n",
    "    \"Lobby\",\n",
    "    \"Entrance hall\",\n",
    "    \"Kitchen\",\n",
    "    \"Family room\",\n",
    "    \"Master bedroom\",\n",
    "    \"Bedroom\",\n",
    "    \"Kids bedroom\",\n",
    "    \"Laundry room\",\n",
    "    \"Guest room\",\n",
    "    \"Home office\",\n",
    "    \"Library room\",\n",
    "    \"Playroom\",\n",
    "    \"Home Theater room\",\n",
    "    \"Gym room\",\n",
    "    \"Basement room\",\n",
    "    \"Garage\",\n",
    "    \"Walk-in closet\",\n",
    "    \"Pantry\",\n",
    "    \"Gaming room\",\n",
    "    \"Attic\",\n",
    "    \"Sunroom\",\n",
    "    \"Storage room\",\n",
    "    \"Study room\",\n",
    "    \"Dining room\",\n",
    "    \"Loft\",\n",
    "    \"Studio room\",\n",
    "    \"Appartement\",\n",
    "]\n",
    "\n",
    "\n",
    "def make_interior_prompt(room: str, prefix: str, style: str) -> str:\n",
    "    \"\"\"Generate a prompt for the interior design model.\n",
    "\n",
    "    Args:\n",
    "        room: room name\n",
    "        prefix: prefix for the room\n",
    "        style: interior style\n",
    "\n",
    "    Returns:\n",
    "        prompt for the interior design model\n",
    "    \"\"\"\n",
    "    return f\"{prefix.lower()} {room.lower()}, {style.lower()} interior design\"\n",
    "\n",
    "\n",
    "class GeneratePromptsComponent(DaskLoadComponent):\n",
    "    def __init__(self, *args, n_rows_to_load: t.Optional[int]) -> None:\n",
    "        \"\"\"\n",
    "        Generate a set of initial prompts that will be used to retrieve images from the\n",
    "        LAION-5B dataset.\n",
    "\n",
    "        Args:\n",
    "            n_rows_to_load: Optional argument that defines the number of rows to load.\n",
    "                Useful for testing pipeline runs on a small scale\n",
    "        \"\"\"\n",
    "        self.n_rows_to_load = n_rows_to_load\n",
    "\n",
    "    def load(self) -> dd.DataFrame:\n",
    "        room_tuples = itertools.product(rooms, interior_prefix, interior_styles)\n",
    "        prompts = map(lambda x: make_interior_prompt(*x), room_tuples)\n",
    "\n",
    "        pandas_df = pd.DataFrame(prompts, columns=[\"prompts_text\"])\n",
    "\n",
    "        if self.n_rows_to_load:\n",
    "            pandas_df = pandas_df.head(self.n_rows_to_load)\n",
    "\n",
    "        df = dd.from_pandas(pandas_df, npartitions=1)\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you now recompile your pipeline, the new changes will be picked up and Fondant will automatically re-build the component with the changes included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DockerCompiler().compile(pipeline=pipeline, output_path=\"docker-compose.yml\")\n",
    "DockerRunner().run(\"docker-compose.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you restart the Explorer, you'll see that you can now select a second pipeline in the left panel and inspect your new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_explorer_app(\n",
    "    base_path=BASE_PATH,\n",
    "    container=\"fndnt/data_explorer\",\n",
    "    tag=\"latest\",\n",
    "    port=8501,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling up\n",
    "\n",
    "If you're happy with your dataset, it's time to scale up. Check [our documentation](https://fondant.ai/en/latest/pipeline/#compiling-and-running-a-pipeline) for more information about the available runners."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
